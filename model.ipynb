{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A2_CRF_dinosaur.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhkDhw5Dz7-e",
        "colab_type": "text"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bg_aj9Uvyt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import dataset\n",
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "val_df = pd.read_csv('val.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgT6qj_Twp09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get labels\n",
        "train_label_raw = list(train_df.NER)\n",
        "val_label_raw = list(val_df.NER)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qe4hdIeCL07_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the labels \n",
        "train_labels = []\n",
        "for label in train_label_raw:\n",
        "    train_labels.append(label.split(\" \"))\n",
        "\n",
        "val_labels = []\n",
        "for label in val_label_raw:\n",
        "    val_labels.append(label.split(\" \"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSkyXNYJ0CK2",
        "colab_type": "text"
      },
      "source": [
        "# 1. Preproccessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVU7Ac3bwczL",
        "colab_type": "code",
        "outputId": "3474ab1d-4850-4149-c792-20a034ac4968",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "\n",
        "# lemmatize the words and lower the word\n",
        "def get_lemmatized_tokens(dataframe):\n",
        "  \"\"\"\n",
        "  Extract sentences from dataframe and output stemmed tokens and related NER\n",
        "  Extract labels from dataframe and tokenize it\n",
        "  \"\"\"\n",
        "  \n",
        "  sentences = list(dataframe.Sentence)\n",
        "\n",
        "  tokenized_sentences = []\n",
        "  for sentence in sentences:\n",
        "    tokens = sentence.split(\" \")\n",
        "    for x in tokens:\n",
        "        x.lower()\n",
        "    tokenized_sentences.append(tokens)\n",
        "\n",
        "  lemmatized_sentences = []\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  for sentence in tokenized_sentences:\n",
        "    lemmatized = [lemmatizer.lemmatize(word, pos='v') for word in sentence]\n",
        "    lemmatized_sentences.append(lemmatized)\n",
        "\n",
        "  return lemmatized_sentences"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_3Jvmehwt5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokens = get_lemmatized_tokens(train_df)\n",
        "val_tokens = get_lemmatized_tokens(val_df)\n",
        "test_tokens = get_lemmatized_tokens(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1-kfghs1vXL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_tokens = train_tokens + val_tokens + test_tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWVnBC6bxC69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference Lab 9 Code: https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "# make mapping between word and index , tag and index\n",
        "word_to_ix = {}\n",
        "for sentence in all_tokens:\n",
        "    for word in sentence:\n",
        "        word = word.lower()\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "word_list = list(word_to_ix.keys())\n",
        "\n",
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "tag_to_ix = {START_TAG:0, STOP_TAG:1}\n",
        "\n",
        "for tags in train_labels:\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGi15x663Y8W",
        "colab_type": "text"
      },
      "source": [
        "# 2. Input Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9uJk1VM3eam",
        "colab_type": "text"
      },
      "source": [
        "##2.1. POS-Tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0lt3-2UzNJ4",
        "colab_type": "code",
        "outputId": "3f21ebfe-68c0-41e3-8670-d1648eebf1d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# function to do the pos tagging for each sentence \n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "def generate_pos_tag(doc):\n",
        "  \"\"\"\n",
        "\n",
        "  :param doc_words: words in doc\n",
        "  :return: pos tags\n",
        "  \"\"\"\n",
        "  pos_tags = []\n",
        "  for sentence in doc:\n",
        "    tags = []\n",
        "    for word, tag in nltk.pos_tag(sentence):\n",
        "      tags.append(tag)\n",
        "    pos_tags.append(tags)\n",
        " \n",
        "  return pos_tags\n",
        "\n",
        "pos_tags = generate_pos_tag(all_tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeSFWQkazWO6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use word2vec to train the embeddings for pos\n",
        "from gensim.models import Word2Vec\n",
        "w2v_pos = Word2Vec(sentences=pos_tags, \n",
        "                   size=20, \n",
        "                   window=3,\n",
        "                   min_count=1,\n",
        "                   workers=4,\n",
        "                   sg=1\n",
        "    \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWG_uUwL3jsM",
        "colab_type": "text"
      },
      "source": [
        "##2.2. Parse Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD06BJhhzexh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference Lab 7 Code: https://colab.research.google.com/drive/1r6LqTob5l1W3hFpmg6ZQ5XgyYulOfCuc\n",
        "\n",
        "import spacy\n",
        "\n",
        "#load the spacy api with the pre-trained statistical models for English. English multi-task CNN trained on OntoNotes\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def parse_sentence(data):\n",
        "    parse_sentences_temp=[]\n",
        "    for sentence in data:\n",
        "        parse = nlp(' '.join(sentence))\n",
        "        deps = []\n",
        "        for x in parse:\n",
        "          deps.append(x.dep_)\n",
        "\n",
        "        parse_sentences_temp.append(deps[:len(sentence)])\n",
        "\n",
        "    return parse_sentences_temp\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKIV_BYBzgmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "parse_sentences=parse_sentence(all_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR_prF4czjE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use word2vec to train the embeddings for pos\n",
        "from gensim.models import Word2Vec\n",
        "w2v_parse_tree = Word2Vec(sentences=parse_sentences, \n",
        "                   size=20, \n",
        "                   window=3,\n",
        "                   min_count=1,\n",
        "                   workers=4,\n",
        "                   sg=1\n",
        "    \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLHZ718kDYaq",
        "colab_type": "code",
        "outputId": "7691d15c-0f20-4514-cc3e-4d43cf13636d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#make a dic about the word and pos,  word and parse tree\n",
        "word_2_pos={}\n",
        "for i in range(0,len(all_tokens)):\n",
        "    for x in range(0,len(all_tokens[i])):\n",
        "        word_2_pos[all_tokens[i][x]] = w2v_pos[pos_tags[i][x]]\n",
        "\n",
        "word_2_pt={}\n",
        "for i in range(0,len(all_tokens)):\n",
        "    for x in range(0,len(all_tokens[i])):\n",
        "        word_2_pt[all_tokens[i][x]] = w2v_parse_tree[parse_sentences[i][x]]       \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjNQG77M3PfT",
        "colab_type": "text"
      },
      "source": [
        "##2.3. Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDzQrWpvrKGD",
        "colab_type": "code",
        "outputId": "c0cd7026-7c6e-49aa-db90-d812da7d9431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Reference Lab 9 Code: https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "#load the glove pre-trained word embedding \n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "word_emb_model = api.load(\"glove-twitter-100\") \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HnkORdXxQKU",
        "colab_type": "code",
        "outputId": "1efa76ea-5d74-44f8-f411-08c39f0788fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "# splice all embeddings pos, parse tree and word embedding \n",
        "EMBEDDING_DIM = 140\n",
        "\n",
        "embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        word_embedding_temp=word_emb_model.wv[word]\n",
        "        word_embedding_temp.extend(word_2_pos[word])\n",
        "        word_embedding_temp.extend(word_2_pt[word])\n",
        "\n",
        "        embedding_matrix.append(word_embedding_temp)\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:253: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12551, 140)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6jOjs0NxWNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference Lab9 Code: https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "# transfer word to index\n",
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "train_input_index =  to_index(train_tokens,word_to_ix)\n",
        "train_output_index = to_index(train_labels,tag_to_ix)\n",
        "val_input_index = to_index(val_tokens,word_to_ix)\n",
        "val_output_index = to_index(val_labels,tag_to_ix)\n",
        "test_input_index = to_index(test_tokens,word_to_ix)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIGmswxiVypw",
        "colab_type": "code",
        "outputId": "930efecb-6ca7-4b2a-f3e4-1a7ed2b7c281",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "tag_to_ix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<START>': 0,\n",
              " '<STOP>': 1,\n",
              " 'I-LOC': 6,\n",
              " 'I-MISC': 4,\n",
              " 'I-ORG': 3,\n",
              " 'I-PER': 5,\n",
              " 'O': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzFV8QeSxYv1",
        "colab_type": "text"
      },
      "source": [
        "# 3. Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96TaWW_exa56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Reference: Lab9 Code https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "#BiLSTM and CRF model with attention\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, attention_method = None):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.attention_method = attention_method\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size) if not attention_method else nn.Linear(hidden_dim * 2, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "        print(self.transitions.shape)\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "        \n",
        "\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "\n",
        "        ##self attention part\n",
        "        if self.attention_method:\n",
        "            lstm_out = torch.squeeze(lstm_out, 1)\n",
        "            left_self = lstm_out.view(1, lstm_out.size(0), lstm_out.size(1))\n",
        "            right_self = left_self.view(left_self.size(0), left_self.size(2), left_self.size(1))\n",
        "            if \"scale\" in self.attention_method.lower():\n",
        "                weight_att = nn.functional.softmax(torch.bmm(left_self, right_self) * 1/np.sqrt(self.hidden_dim * 2),dim=-1)\n",
        "            else:\n",
        "                weight_att = nn.functional.softmax(torch.bmm(left_self, right_self),dim=-1)\n",
        "\n",
        "            output = torch.bmm(weight_att, left_self)\n",
        "            concat_output = torch.cat((output, left_self), dim = -1)\n",
        "            lstm_out = concat_output.view(len(sentence), self.hidden_dim * 2)\n",
        "        else:\n",
        "            lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  \n",
        "        # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLo9Tcuzxg6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the F1 score of the model on specific data set\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "def cal_acc(model, input_index, output_index):\n",
        "    ground_truth=[]\n",
        "    predicted=[]\n",
        "    for x,y in zip(input_index,output_index):\n",
        "        input_tensor = torch.tensor(x).to(device)\n",
        "        _,output = model(input_tensor)\n",
        "        ground_truth.extend(y)\n",
        "        predicted.extend(output)\n",
        "\n",
        "    f1score=f1_score(ground_truth,predicted,average = 'micro')\n",
        "    return ground_truth, predicted, f1score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m25gxQRM5Cy1",
        "colab_type": "text"
      },
      "source": [
        "#4. Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ho8xCYcy4cVJ",
        "colab_type": "text"
      },
      "source": [
        "##4.1. Different Embedding Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1cxp0dX5vh3",
        "colab_type": "text"
      },
      "source": [
        "###4.1.1. Word Embedding + POS-Tag + Parse Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKKrJKyvxm6l",
        "colab_type": "code",
        "outputId": "c8d7433a-b3d2-4e4b-bb52-9c1e2ae15287",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "HIDDEN_DIM = 200\n",
        "\n",
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, attention_method = None).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.015, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny6GrY7JCT50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data=train_input_index+val_input_index\n",
        "train_label=train_output_index+val_output_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBj_PVnNxqHr",
        "colab_type": "code",
        "outputId": "f54c706d-811b-43df-e684-6de03939ad8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "\"\"\"Each epoch will take about 2-3 minutes\"\"\"\n",
        "import datetime\n",
        "\n",
        "# Reference Lab 9 Code: https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "# train the model \n",
        "for epoch in range(15):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    max_val_acc=0\n",
        "    model.eval()\n",
        "    _, _, train_acc = cal_acc(model,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model,val_input_index,val_output_index)\n",
        "\n",
        "    #pick the best model which has the biggest F1 score on val data\n",
        "    if(val_acc>max_val_acc):\n",
        "        best_model = model\n",
        "        max_val_acc=val_acc\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train f1 score: %.4f, val loss: %.2f, val f1 score: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 23357.76, train f1 score: 0.8192, val loss: 4589.63, val f1 score: 0.7742, time: 144.35s\n",
            "Epoch:2, Training loss: 12087.14, train f1 score: 0.8848, val loss: 2804.40, val f1 score: 0.8408, time: 143.29s\n",
            "Epoch:3, Training loss: 7193.52, train f1 score: 0.9215, val loss: 2762.07, val f1 score: 0.8630, time: 142.87s\n",
            "Epoch:4, Training loss: 5347.25, train f1 score: 0.9337, val loss: 3029.42, val f1 score: 0.8653, time: 142.82s\n",
            "Epoch:5, Training loss: 3981.20, train f1 score: 0.9548, val loss: 2862.78, val f1 score: 0.8809, time: 145.22s\n",
            "Epoch:6, Training loss: 3150.10, train f1 score: 0.9673, val loss: 2774.34, val f1 score: 0.8837, time: 144.42s\n",
            "Epoch:7, Training loss: 2627.87, train f1 score: 0.9728, val loss: 2801.75, val f1 score: 0.8892, time: 143.15s\n",
            "Epoch:8, Training loss: 2215.53, train f1 score: 0.9734, val loss: 3089.81, val f1 score: 0.8890, time: 144.20s\n",
            "Epoch:9, Training loss: 1963.97, train f1 score: 0.9811, val loss: 2835.24, val f1 score: 0.9048, time: 146.20s\n",
            "Epoch:10, Training loss: 1655.81, train f1 score: 0.9815, val loss: 2656.34, val f1 score: 0.9009, time: 144.48s\n",
            "Epoch:11, Training loss: 1409.71, train f1 score: 0.9844, val loss: 3026.93, val f1 score: 0.9112, time: 142.84s\n",
            "Epoch:12, Training loss: 1245.54, train f1 score: 0.9861, val loss: 3070.45, val f1 score: 0.9103, time: 143.71s\n",
            "Epoch:13, Training loss: 1074.56, train f1 score: 0.9873, val loss: 3267.94, val f1 score: 0.9099, time: 146.63s\n",
            "Epoch:14, Training loss: 906.81, train f1 score: 0.9904, val loss: 3242.03, val f1 score: 0.9107, time: 144.13s\n",
            "Epoch:15, Training loss: 798.86, train f1 score: 0.9913, val loss: 3319.32, val f1 score: 0.9109, time: 144.49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvmaOgoVAKU8",
        "colab_type": "text"
      },
      "source": [
        "### 4.1.2. Word Embedding + Pos-Tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdxC4LAuARal",
        "colab_type": "code",
        "outputId": "9903f5c2-607a-41d3-c5f0-f66eb53787f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "EMBEDDING_DIM = 120\n",
        "# splice the pos and word embedding\n",
        "embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        word_embedding_temp=word_emb_model.wv[word]\n",
        "        word_embedding_temp.extend(word_2_pos[word])\n",
        "\n",
        "        embedding_matrix.append(word_embedding_temp)\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12551, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grYph5OEBSc6",
        "colab_type": "code",
        "outputId": "cb6b4a6e-1d2a-4142-91e7-37e4ae771231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model_w_p = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, attention_method = None).to(device)\n",
        "optimizer1= optim.SGD(model_w_p.parameters(), lr=0.015, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIRtI3ieBhjy",
        "colab_type": "code",
        "outputId": "d19d9e30-14ba-4318-d747-ddb85cf07485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "\"\"\"Each epoch will take about 2-3 minutes\"\"\"\n",
        "import datetime\n",
        "\n",
        "# Reference Lab 9 Code: https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "\n",
        "for epoch in range(15):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_w_p.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_w_p.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_w_p.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer1.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    max_val_acc=0\n",
        "    model_w_p.eval()\n",
        "    _, _, train_acc = cal_acc(model_w_p,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_w_p,val_input_index,val_output_index)\n",
        "\n",
        "    if(val_acc>max_val_acc):\n",
        "        best_model = model_w_p\n",
        "        max_val_acc=val_acc\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_w_p.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train f1 score: %.4f, val loss: %.2f, val f1 score: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 23395.54, train f1 score: 0.8143, val loss: 4958.59, val f1 score: 0.7664, time: 140.38s\n",
            "Epoch:2, Training loss: 12758.37, train f1 score: 0.8782, val loss: 2894.08, val f1 score: 0.8363, time: 138.89s\n",
            "Epoch:3, Training loss: 7656.35, train f1 score: 0.9203, val loss: 2753.11, val f1 score: 0.8684, time: 141.06s\n",
            "Epoch:4, Training loss: 5464.88, train f1 score: 0.9386, val loss: 2764.70, val f1 score: 0.8736, time: 143.27s\n",
            "Epoch:5, Training loss: 4060.91, train f1 score: 0.9581, val loss: 2682.26, val f1 score: 0.8829, time: 139.41s\n",
            "Epoch:6, Training loss: 3200.77, train f1 score: 0.9605, val loss: 3049.03, val f1 score: 0.8827, time: 140.48s\n",
            "Epoch:7, Training loss: 2653.24, train f1 score: 0.9669, val loss: 3155.78, val f1 score: 0.8839, time: 139.07s\n",
            "Epoch:8, Training loss: 2257.03, train f1 score: 0.9719, val loss: 2727.83, val f1 score: 0.8816, time: 141.81s\n",
            "Epoch:9, Training loss: 1923.67, train f1 score: 0.9800, val loss: 2757.10, val f1 score: 0.8936, time: 143.70s\n",
            "Epoch:10, Training loss: 1714.34, train f1 score: 0.9787, val loss: 3152.05, val f1 score: 0.8888, time: 142.49s\n",
            "Epoch:11, Training loss: 1452.57, train f1 score: 0.9852, val loss: 2525.76, val f1 score: 0.9120, time: 141.89s\n",
            "Epoch:12, Training loss: 1320.49, train f1 score: 0.9856, val loss: 2976.06, val f1 score: 0.9050, time: 143.53s\n",
            "Epoch:13, Training loss: 1179.59, train f1 score: 0.9883, val loss: 2915.55, val f1 score: 0.9105, time: 145.42s\n",
            "Epoch:14, Training loss: 1101.84, train f1 score: 0.9875, val loss: 2924.11, val f1 score: 0.9182, time: 142.50s\n",
            "Epoch:15, Training loss: 908.27, train f1 score: 0.9903, val loss: 3001.20, val f1 score: 0.9191, time: 142.26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5fifxSoUWhT",
        "colab_type": "text"
      },
      "source": [
        "### 4.1.3 word embedding + Parse Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJkTGzv_UWJY",
        "colab_type": "code",
        "outputId": "19807029-59ff-456f-9475-a470e20df409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "EMBEDDING_DIM = 120\n",
        "# splice the word embedding and parse tree\n",
        "embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        word_embedding_temp=word_emb_model.wv[word]\n",
        "        word_embedding_temp.extend(word_2_pt[word])\n",
        "\n",
        "        embedding_matrix.append(word_embedding_temp)\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12551, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8YWzA_YU3qb",
        "colab_type": "code",
        "outputId": "73f0ba9a-da0f-4bb0-a9dc-3bd197c6b8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model_w_pt = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, attention_method = None).to(device)\n",
        "optimizer2= optim.SGD(model_w_pt.parameters(), lr=0.015, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiwdwoRJU8FH",
        "colab_type": "code",
        "outputId": "11f73759-9b29-41f7-bddb-aa4ac189251a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "\"\"\"Each epoch will take about 2-3 minutes\"\"\"\n",
        "import datetime\n",
        "\n",
        "# Reference Lab 9 Code: https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "# train\n",
        "for epoch in range(15):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_w_pt.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_w_pt.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_w_pt.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer2.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    max_val_acc=0\n",
        "    model_w_pt.eval()\n",
        "    _, _, train_acc = cal_acc(model_w_pt,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_w_pt,val_input_index,val_output_index)\n",
        "\n",
        "    if(val_acc>max_val_acc):\n",
        "        best_model = model_w_p\n",
        "        max_val_acc=val_acc\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_w_pt.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train f1 score: %.4f, val loss: %.2f, val f1 score: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 23453.19, train f1 score: 0.8133, val loss: 5131.74, val f1 score: 0.7676, time: 141.28s\n",
            "Epoch:2, Training loss: 12855.27, train f1 score: 0.8777, val loss: 2827.09, val f1 score: 0.8415, time: 143.11s\n",
            "Epoch:3, Training loss: 7199.73, train f1 score: 0.9274, val loss: 2579.76, val f1 score: 0.8747, time: 140.90s\n",
            "Epoch:4, Training loss: 4852.70, train f1 score: 0.9483, val loss: 2717.20, val f1 score: 0.8793, time: 141.62s\n",
            "Epoch:5, Training loss: 3508.58, train f1 score: 0.9565, val loss: 2842.28, val f1 score: 0.8801, time: 140.97s\n",
            "Epoch:6, Training loss: 2831.20, train f1 score: 0.9669, val loss: 2758.99, val f1 score: 0.8816, time: 143.68s\n",
            "Epoch:7, Training loss: 2366.47, train f1 score: 0.9714, val loss: 2928.31, val f1 score: 0.8826, time: 140.46s\n",
            "Epoch:8, Training loss: 2120.89, train f1 score: 0.9737, val loss: 3124.29, val f1 score: 0.8949, time: 142.96s\n",
            "Epoch:9, Training loss: 1822.63, train f1 score: 0.9782, val loss: 2774.40, val f1 score: 0.8884, time: 140.32s\n",
            "Epoch:10, Training loss: 1621.80, train f1 score: 0.9823, val loss: 2879.14, val f1 score: 0.8956, time: 139.90s\n",
            "Epoch:11, Training loss: 1424.38, train f1 score: 0.9864, val loss: 2855.91, val f1 score: 0.9101, time: 141.99s\n",
            "Epoch:12, Training loss: 1292.28, train f1 score: 0.9863, val loss: 3084.87, val f1 score: 0.8961, time: 139.92s\n",
            "Epoch:13, Training loss: 1162.08, train f1 score: 0.9893, val loss: 3069.74, val f1 score: 0.9140, time: 140.46s\n",
            "Epoch:14, Training loss: 1007.03, train f1 score: 0.9900, val loss: 3006.50, val f1 score: 0.9035, time: 139.35s\n",
            "Epoch:15, Training loss: 870.36, train f1 score: 0.9914, val loss: 3058.02, val f1 score: 0.9136, time: 142.03s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d4S1GXxma1O",
        "colab_type": "text"
      },
      "source": [
        "##4.2. Different Attention Strategy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VqrUcuUjFmG",
        "colab_type": "text"
      },
      "source": [
        "### 4.2.1. word embedding + Pos-Tag + Scale Dot Attention Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzchtzyrin-R",
        "colab_type": "code",
        "outputId": "cb8b037e-05a3-4674-8e33-f68d81f0b54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "EMBEDDING_DIM = 120\n",
        "\n",
        "embedding_matrix = []\n",
        "for word in word_list:\n",
        "    try:\n",
        "        word_embedding_temp=word_emb_model.wv[word]\n",
        "        word_embedding_temp.extend(word_2_pos[word])\n",
        "\n",
        "        embedding_matrix.append(word_embedding_temp)\n",
        "    except:\n",
        "        embedding_matrix.append([0]*EMBEDDING_DIM)\n",
        "embedding_matrix = np.array(embedding_matrix)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12551, 120)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3KJlpBgjSCh",
        "colab_type": "code",
        "outputId": "f4244310-0b43-4ff7-be3a-890c0a68a24d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#using scale score to calculate the attention score\n",
        "model_w_p = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, attention_method = \"scale\").to(device)\n",
        "optimizer1 = optim.SGD(model_w_p.parameters(), lr=0.015, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDrW-fcujdd2",
        "colab_type": "code",
        "outputId": "88f6d8a2-208e-44b3-c138-889d782042b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "\"\"\"Each epoch will take about 2-3 minutes\"\"\"\n",
        "import datetime\n",
        "\n",
        "# Reference Lab 9 Code: https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "\n",
        "for epoch in range(15):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_w_p.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_w_p.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_w_p.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer1.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    max_val_acc=0\n",
        "    model_w_p.eval()\n",
        "    _, _, train_acc = cal_acc(model_w_p,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_w_p,val_input_index,val_output_index)\n",
        "\n",
        "    if(val_acc>max_val_acc):\n",
        "        best_model = model_w_p\n",
        "        max_val_acc=val_acc\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_w_p.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train f1 score: %.4f, val loss: %.2f, val f1 score: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 23573.80, train f1 score: 0.8129, val loss: 5284.52, val f1 score: 0.7663, time: 136.23s\n",
            "Epoch:2, Training loss: 13324.92, train f1 score: 0.8788, val loss: 2800.39, val f1 score: 0.8463, time: 134.56s\n",
            "Epoch:3, Training loss: 7771.00, train f1 score: 0.9150, val loss: 2819.19, val f1 score: 0.8645, time: 134.16s\n",
            "Epoch:4, Training loss: 5553.85, train f1 score: 0.9359, val loss: 2776.16, val f1 score: 0.8733, time: 134.43s\n",
            "Epoch:5, Training loss: 4091.56, train f1 score: 0.9536, val loss: 2728.55, val f1 score: 0.8806, time: 134.92s\n",
            "Epoch:6, Training loss: 3122.22, train f1 score: 0.9675, val loss: 2667.39, val f1 score: 0.9001, time: 137.51s\n",
            "Epoch:7, Training loss: 2547.59, train f1 score: 0.9732, val loss: 2710.82, val f1 score: 0.8980, time: 135.96s\n",
            "Epoch:8, Training loss: 2139.21, train f1 score: 0.9793, val loss: 2719.76, val f1 score: 0.9058, time: 135.75s\n",
            "Epoch:9, Training loss: 1823.31, train f1 score: 0.9818, val loss: 2474.06, val f1 score: 0.9079, time: 135.39s\n",
            "Epoch:10, Training loss: 1633.24, train f1 score: 0.9833, val loss: 2717.62, val f1 score: 0.9105, time: 137.87s\n",
            "Epoch:11, Training loss: 1423.18, train f1 score: 0.9866, val loss: 2717.91, val f1 score: 0.9116, time: 135.81s\n",
            "Epoch:12, Training loss: 1300.43, train f1 score: 0.9882, val loss: 2567.52, val f1 score: 0.9193, time: 136.53s\n",
            "Epoch:13, Training loss: 1152.81, train f1 score: 0.9891, val loss: 2688.80, val f1 score: 0.9209, time: 136.53s\n",
            "Epoch:14, Training loss: 984.77, train f1 score: 0.9882, val loss: 3027.48, val f1 score: 0.9205, time: 138.70s\n",
            "Epoch:15, Training loss: 922.44, train f1 score: 0.9900, val loss: 3023.62, val f1 score: 0.9238, time: 137.71s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6jAaTAtqN47",
        "colab_type": "code",
        "outputId": "f1fd338e-2e03-428c-daeb-bfba5f9203cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "# get the details about the performance of our model\n",
        "y_true,y_pred,_ = cal_acc(best_model,val_input_index,val_output_index)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_pred,digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2     0.9284    0.9870    0.9568      5790\n",
            "           3     0.7143    0.4912    0.5821       285\n",
            "           4     0.8030    0.5668    0.6646       187\n",
            "           5     0.9444    0.7566    0.8401       875\n",
            "           6     0.9353    0.8282    0.8785       419\n",
            "\n",
            "    accuracy                         0.9224      7556\n",
            "   macro avg     0.8651    0.7260    0.7844      7556\n",
            "weighted avg     0.9194    0.9224    0.9176      7556\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wq4rjBSuW-j",
        "colab_type": "text"
      },
      "source": [
        "### 4.2.2. Word embedding + Pos-Tag + Dot Attention Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIGx7oSLuhTt",
        "colab_type": "code",
        "outputId": "4bd8b109-90c6-4d31-8e97-3a6e0da68413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#using dot score to calculate the attention score\n",
        "model_w_p_dot = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, attention_method = \"dot\").to(device)\n",
        "optimizer3 = optim.SGD(model_w_p_dot.parameters(), lr=0.015, weight_decay=1e-4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqVVgr4cupE9",
        "colab_type": "code",
        "outputId": "732ca1a1-d554-4889-87a3-d7c61650dd1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "\"\"\"Each epoch will take about 2-3 minutes\"\"\"\n",
        "import datetime\n",
        "\n",
        "# Reference Lab 9 Code: https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "\n",
        "for epoch in range(20):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_w_p_dot.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_w_p_dot.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_w_p_dot.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer3.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    max_val_acc=0\n",
        "    model_w_p_dot.eval()\n",
        "    _, _, train_acc = cal_acc(model_w_p_dot,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_w_p_dot,val_input_index,val_output_index)\n",
        "\n",
        "    if(val_acc>max_val_acc):\n",
        "        best_model = model_w_p_dot\n",
        "        max_val_acc=val_acc\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_w_p_dot.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train f1 score: %.4f, val loss: %.2f, val f1 score: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 23603.51, train f1 score: 0.8125, val loss: 5250.11, val f1 score: 0.7657, time: 136.32s\n",
            "Epoch:2, Training loss: 13329.52, train f1 score: 0.8805, val loss: 2876.43, val f1 score: 0.8446, time: 137.73s\n",
            "Epoch:3, Training loss: 7823.88, train f1 score: 0.9157, val loss: 2805.69, val f1 score: 0.8657, time: 134.86s\n",
            "Epoch:4, Training loss: 5626.14, train f1 score: 0.9387, val loss: 2732.35, val f1 score: 0.8733, time: 134.66s\n",
            "Epoch:5, Training loss: 4178.54, train f1 score: 0.9510, val loss: 2919.32, val f1 score: 0.8804, time: 134.81s\n",
            "Epoch:6, Training loss: 3309.43, train f1 score: 0.9623, val loss: 2897.64, val f1 score: 0.8846, time: 135.17s\n",
            "Epoch:7, Training loss: 2619.83, train f1 score: 0.9730, val loss: 2605.73, val f1 score: 0.9010, time: 136.54s\n",
            "Epoch:8, Training loss: 2271.14, train f1 score: 0.9767, val loss: 2634.22, val f1 score: 0.8968, time: 134.64s\n",
            "Epoch:9, Training loss: 1971.51, train f1 score: 0.9788, val loss: 2857.49, val f1 score: 0.8968, time: 134.88s\n",
            "Epoch:10, Training loss: 1612.60, train f1 score: 0.9843, val loss: 2780.76, val f1 score: 0.9068, time: 134.79s\n",
            "Epoch:11, Training loss: 1452.33, train f1 score: 0.9855, val loss: 2721.71, val f1 score: 0.9026, time: 137.08s\n",
            "Epoch:12, Training loss: 1266.88, train f1 score: 0.9831, val loss: 3424.03, val f1 score: 0.8999, time: 133.77s\n",
            "Epoch:13, Training loss: 1144.39, train f1 score: 0.9885, val loss: 2796.79, val f1 score: 0.9088, time: 134.32s\n",
            "Epoch:14, Training loss: 995.11, train f1 score: 0.9916, val loss: 2902.42, val f1 score: 0.9177, time: 135.28s\n",
            "Epoch:15, Training loss: 786.59, train f1 score: 0.9926, val loss: 2932.79, val f1 score: 0.9156, time: 134.15s\n",
            "Epoch:16, Training loss: 756.13, train f1 score: 0.9935, val loss: 3070.94, val f1 score: 0.9169, time: 136.25s\n",
            "Epoch:17, Training loss: 759.69, train f1 score: 0.9938, val loss: 3139.53, val f1 score: 0.9183, time: 133.72s\n",
            "Epoch:18, Training loss: 619.87, train f1 score: 0.9950, val loss: 3109.21, val f1 score: 0.9202, time: 134.78s\n",
            "Epoch:19, Training loss: 504.89, train f1 score: 0.9944, val loss: 3581.81, val f1 score: 0.9112, time: 134.90s\n",
            "Epoch:20, Training loss: 425.33, train f1 score: 0.9966, val loss: 3316.45, val f1 score: 0.9228, time: 137.90s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrbQBqUjuzLp",
        "colab_type": "code",
        "outputId": "519a2a32-7488-48a1-cb60-c63008832310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        }
      },
      "source": [
        "y_true,y_pred,_ = cal_acc(best_model,val_input_index,val_output_index)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_pred,digits=4))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2     0.9273    0.9872    0.9563      5790\n",
            "           3     0.7525    0.5333    0.6242       285\n",
            "           4     0.8906    0.6096    0.7238       187\n",
            "           5     0.9400    0.7337    0.8241       875\n",
            "           6     0.9340    0.8449    0.8872       419\n",
            "\n",
            "    accuracy                         0.9235      7556\n",
            "   macro avg     0.8889    0.7418    0.8031      7556\n",
            "weighted avg     0.9217    0.9235    0.9189      7556\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ovsB-HWH5ZE",
        "colab_type": "text"
      },
      "source": [
        "## different layers model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDidFBhZJ1b5",
        "colab_type": "text"
      },
      "source": [
        "### 2 layers LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EQ6gJHuH9VI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Reference: Lab9 Code https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, attention_method = None):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "        self.attention_method = attention_method\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=2, bidirectional=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size) if not attention_method else nn.Linear(hidden_dim * 2, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "        print(self.transitions.shape)\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(4, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(4, 1, self.hidden_dim // 2).to(device))\n",
        "        \n",
        "\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "\n",
        "        ##self attention part\n",
        "        if self.attention_method:\n",
        "            lstm_out = torch.squeeze(lstm_out, 1)\n",
        "            left_self = lstm_out.view(1, lstm_out.size(0), lstm_out.size(1))\n",
        "            right_self = left_self.view(left_self.size(0), left_self.size(2), left_self.size(1))\n",
        "            if \"scale\" in self.attention_method.lower():\n",
        "                weight_att = nn.functional.softmax(torch.bmm(left_self, right_self) * 1/np.sqrt(self.hidden_dim * 2),dim=-1)\n",
        "            else:\n",
        "                weight_att = nn.functional.softmax(torch.bmm(left_self, right_self),dim=-1)\n",
        "\n",
        "            output = torch.bmm(weight_att, left_self)\n",
        "            concat_output = torch.cat((output, left_self), dim = -1)\n",
        "            lstm_out = concat_output.view(len(sentence), self.hidden_dim * 2)\n",
        "        else:\n",
        "            lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  \n",
        "        # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTTfBpXGIyBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "74894924-322c-44ea-cc39-204b3e090f62"
      },
      "source": [
        "model_2_layer = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM, attention_method = \"scale\").to(device)\n",
        "optimizer4 = optim.SGD(model_2_layer.parameters(), lr=0.03, weight_decay=1e-4)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([7, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0-IzPrwI3fR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "de954583-4e4b-4c29-d670-04b71399f8a2"
      },
      "source": [
        "\"\"\"Each epoch will take about 2-3 minutes\"\"\"\n",
        "import datetime\n",
        "\n",
        "# Reference Lab 9 Code: https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "\n",
        "for epoch in range(20):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_2_layer.train()\n",
        "    for i, idxs in enumerate(train_input_index):\n",
        "        tags_index = train_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_2_layer.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_2_layer.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer4.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    max_val_acc=0\n",
        "    model_2_layer.eval()\n",
        "    _, _, train_acc = cal_acc(model_2_layer,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_2_layer,val_input_index,val_output_index)\n",
        "\n",
        "    if(val_acc>max_val_acc):\n",
        "        best_model = model_2_layer\n",
        "        max_val_acc=val_acc\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_2_layer.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train f1 score: %.4f, val loss: %.2f, val f1 score: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 23932.20, train f1 score: 0.8119, val loss: 6012.05, val f1 score: 0.7663, time: 186.30s\n",
            "Epoch:2, Training loss: 17897.54, train f1 score: 0.8446, val loss: 3442.49, val f1 score: 0.8065, time: 182.20s\n",
            "Epoch:3, Training loss: 8896.50, train f1 score: 0.9152, val loss: 2601.96, val f1 score: 0.8808, time: 190.15s\n",
            "Epoch:4, Training loss: 5631.97, train f1 score: 0.9414, val loss: 2144.41, val f1 score: 0.8985, time: 192.82s\n",
            "Epoch:5, Training loss: 3933.50, train f1 score: 0.9543, val loss: 2318.39, val f1 score: 0.9052, time: 189.63s\n",
            "Epoch:6, Training loss: 2974.72, train f1 score: 0.9562, val loss: 2391.04, val f1 score: 0.9031, time: 180.36s\n",
            "Epoch:7, Training loss: 2374.33, train f1 score: 0.9659, val loss: 2400.77, val f1 score: 0.9112, time: 191.10s\n",
            "Epoch:8, Training loss: 1919.19, train f1 score: 0.9478, val loss: 3173.46, val f1 score: 0.8629, time: 179.49s\n",
            "Epoch:9, Training loss: 1588.40, train f1 score: 0.9761, val loss: 2549.12, val f1 score: 0.9026, time: 183.58s\n",
            "Epoch:10, Training loss: 1334.24, train f1 score: 0.9728, val loss: 3125.42, val f1 score: 0.9097, time: 188.82s\n",
            "Epoch:11, Training loss: 1032.97, train f1 score: 0.9805, val loss: 3090.70, val f1 score: 0.9145, time: 190.16s\n",
            "Epoch:12, Training loss: 914.49, train f1 score: 0.9810, val loss: 3176.47, val f1 score: 0.9177, time: 188.62s\n",
            "Epoch:13, Training loss: 751.61, train f1 score: 0.9840, val loss: 3549.44, val f1 score: 0.9146, time: 191.10s\n",
            "Epoch:14, Training loss: 702.08, train f1 score: 0.9885, val loss: 2979.10, val f1 score: 0.9205, time: 200.35s\n",
            "Epoch:15, Training loss: 694.37, train f1 score: 0.9911, val loss: 2925.12, val f1 score: 0.9248, time: 189.53s\n",
            "Epoch:16, Training loss: 533.08, train f1 score: 0.9933, val loss: 3381.10, val f1 score: 0.9242, time: 188.69s\n",
            "Epoch:17, Training loss: 532.49, train f1 score: 0.9949, val loss: 2859.40, val f1 score: 0.9317, time: 188.31s\n",
            "Epoch:18, Training loss: 402.26, train f1 score: 0.9954, val loss: 3105.32, val f1 score: 0.9295, time: 201.43s\n",
            "Epoch:19, Training loss: 323.95, train f1 score: 0.9965, val loss: 3097.95, val f1 score: 0.9313, time: 199.73s\n",
            "Epoch:20, Training loss: 552.03, train f1 score: 0.9801, val loss: 3277.66, val f1 score: 0.8948, time: 196.00s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9l1B3YfI9zc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "5614b8f7-eb90-428d-c8c9-4d33b9d80efe"
      },
      "source": [
        "y_true,y_pred,_ = cal_acc(best_model,val_input_index,val_output_index)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true,y_pred,digits=4))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2     0.9151    0.9870    0.9497      5790\n",
            "           3     0.4970    0.5825    0.5363       285\n",
            "           4     0.8652    0.6524    0.7439       187\n",
            "           5     0.9456    0.4571    0.6163       875\n",
            "           6     0.8668    0.8544    0.8606       419\n",
            "\n",
            "    accuracy                         0.8948      7556\n",
            "   macro avg     0.8180    0.7067    0.7414      7556\n",
            "weighted avg     0.8990    0.8948    0.8855      7556\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kqkFfjbi73_",
        "colab_type": "text"
      },
      "source": [
        "Try to feed val data set in our *model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4G3uMZFJxga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2365064b-cbdc-45b9-a6c0-4924ef43d6ff"
      },
      "source": [
        "\"\"\"Each epoch will take about 2-3 minutes\"\"\"\n",
        "import datetime\n",
        "\n",
        "# Reference Lab 9 Code: https://colab.research.google.com/drive/1yVy7T9DNB9lJo3NgFdsHAuEsI0msAuPz\n",
        "\n",
        "for epoch in range(4):  \n",
        "    time1 = datetime.datetime.now()\n",
        "    train_loss = 0\n",
        "\n",
        "    model_2_layer.train()\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "\n",
        "        # Step 1. Remember that Pytorch accumulates gradients.\n",
        "        # We need to clear them out before each instance\n",
        "        model_2_layer.zero_grad()\n",
        "\n",
        "        # Step 2. Get our inputs ready for the network, that is,\n",
        "        # turn them into Tensors of word indices.\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "        # Step 3. Run our forward pass.\n",
        "        loss = model_2_layer.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "        # calling optimizer.step()\n",
        "        loss.backward()\n",
        "        optimizer4.step()\n",
        "\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "    max_val_acc=0\n",
        "    model_2_layer.eval()\n",
        "    _, _, train_acc = cal_acc(model_2_layer,train_input_index,train_output_index)\n",
        "    _, _, val_acc = cal_acc(model_2_layer,val_input_index,val_output_index)\n",
        "\n",
        "    if(val_acc>max_val_acc):\n",
        "        best_model = model_2_layer\n",
        "        max_val_acc=val_acc\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, idxs in enumerate(val_input_index):\n",
        "        tags_index = val_output_index[i]\n",
        "        sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "        targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "        loss = model_2_layer.neg_log_likelihood(sentence_in, targets)\n",
        "        val_loss+=loss.item()\n",
        "    time2 = datetime.datetime.now()\n",
        "\n",
        "    print(\"Epoch:%d, Training loss: %.2f, train f1 score: %.4f, val loss: %.2f, val f1 score: %.4f, time: %.2fs\" %(epoch+1, train_loss,train_acc, val_loss, val_acc, (time2-time1).total_seconds()))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Training loss: 1494.99, train f1 score: 0.9743, val loss: 652.81, val f1 score: 0.9637, time: 69.85s\n",
            "Epoch:2, Training loss: 453.68, train f1 score: 0.9818, val loss: 226.90, val f1 score: 0.9858, time: 69.93s\n",
            "Epoch:3, Training loss: 220.74, train f1 score: 0.9831, val loss: 133.57, val f1 score: 0.9914, time: 70.32s\n",
            "Epoch:4, Training loss: 127.63, train f1 score: 0.9846, val loss: 75.30, val f1 score: 0.9960, time: 69.78s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXiD9xqsxzdv",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wULZlHQqq3jS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "11f19ccc-c1b8-4b96-f923-ae88370c9c06"
      },
      "source": [
        "import torch\n",
        "torch.save(best_model,\"model.pt\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type BiLSTM_CRF. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyLCigMefgek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ix_2_tag={}\n",
        "for x in tag_to_ix.keys():\n",
        "    ix_2_tag[tag_to_ix[x]] = x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDK9YmQZetKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, input_index):\n",
        "    predicted=[]\n",
        "    for x in input_index:\n",
        "        input_tensor = torch.tensor(x).to(device)\n",
        "        _,output = model(input_tensor)\n",
        "        predicted.extend(output)\n",
        "    return predicted\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZCTqrQbp3Xq",
        "colab_type": "code",
        "outputId": "c1aed14a-3e36-47b0-95ff-34c69cc29145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "ix_2_tag"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '<START>',\n",
              " 1: '<STOP>',\n",
              " 2: 'O',\n",
              " 3: 'I-ORG',\n",
              " 4: 'I-MISC',\n",
              " 5: 'I-PER',\n",
              " 6: 'I-LOC'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E_rpEoekq9v",
        "colab_type": "text"
      },
      "source": [
        "make a predition on our test data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdZOagq2n30J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predition = predict(best_model,test_input_index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U48dhGa-pqYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fianl_predition=[]\n",
        "for x in predition:\n",
        "    fianl_predition.append(ix_2_tag[x])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-53qP7XCqAwg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fianl_predition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTVMX_Gto_sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fianl_id = range(0,46666)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMIHv2UjxE2",
        "colab_type": "text"
      },
      "source": [
        "make a CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebw8bKDEfyGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_prediction = {'Id':fianl_id ,'Predicted':fianl_predition }\n",
        "\n",
        "df = pd.DataFrame(test_prediction)\n",
        "\n",
        "df.to_csv('result.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}